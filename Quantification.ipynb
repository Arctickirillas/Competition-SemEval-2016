{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.models.word2vec as w2v\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess, re, time, string, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier  as KNC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_curve,accuracy_score,roc_auc_score\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = w2v.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.similarity('women', 'men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet = 'Today is our refounding moment LinkedIn cofounder Reid Hoffman reflects on joining forces with Microsoft'\n",
    "tweet = tweet.lower().split()\n",
    "\n",
    "tweet_vec = [0]*300\n",
    "for word in tweet:\n",
    "    tweet_vec += model[(word)]\n",
    "tweet_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CC(sequence):\n",
    "    sequence = pd.Series(sequence)\n",
    "    if (len(sequence.value_counts()))>1:\n",
    "        return [value/sequence.count() for value in sequence.value_counts()]\n",
    "    else:\n",
    "        if sum(sequence.get_values()) > 0:\n",
    "            return [0.99, 0.01]\n",
    "        else:\n",
    "            return [0.01, 0.99]\n",
    "def CC(sequence):\n",
    "    sequence = pd.Series(sequence)\n",
    "    if (len(sequence.value_counts()))>1:\n",
    "        return [value/sequence.count() for value in sequence.value_counts()]\n",
    "    else:\n",
    "        if sum(sequence.get_values()) > 0:\n",
    "            return [0.99, 0.01]\n",
    "        else:\n",
    "            return [0.01, 0.99]\n",
    "        \n",
    "def PCC(probabilities):\n",
    "    pcc = (np.average(probabilities.T,axis=1)).tolist()\n",
    "    pcc.reverse()\n",
    "    return pcc\n",
    "\n",
    "def ACC(sequence,fpr,tpr):\n",
    "    sequence = pd.Series(sequence)\n",
    "    acc = [(value/sequence.count() - fpr)/(tpr - fpr) for value in sequence.value_counts()]\n",
    "    \n",
    "    for i,share in enumerate(acc):\n",
    "        if share >= 1.:\n",
    "            acc[i] = 0.99\n",
    "        elif share <= 0.:\n",
    "            acc[i] = 0.01\n",
    "    \n",
    "    acc = normalize(np.array(acc).reshape((1, -1)), norm='l1',axis=1)[0]\n",
    "    \n",
    "    if len(acc)>1:\n",
    "        return acc\n",
    "    else:\n",
    "        if sum(sequence.get_values()) > 0:\n",
    "            return [0.99, 0.01]\n",
    "        else:\n",
    "            return [0.01, 0.99]\n",
    "\n",
    "def PACC(sequence,probabilities,e_fpr,e_tpr):\n",
    "    probabilities = pd.DataFrame(probabilities)\n",
    "    pcc  = PCC(probabilities)\n",
    "    pacc = [min(1.0,(pcc[i] - e_fpr))/max(0.0001,(e_tpr - e_fpr)) for i,column_name in enumerate(probabilities.columns)]    \n",
    "    \n",
    "    for i,item in enumerate(pacc):\n",
    "        if item<0:\n",
    "            pacc[i] = pcc[i]\n",
    "   \n",
    "    pacc = normalize(np.array(pacc).reshape((1, -1)), norm='l1',axis=1)[0]\n",
    "   \n",
    "    return pacc\n",
    "\n",
    "def EM(y_train, pred_prob, stop_delta=0.0001):        \n",
    "        cc = CC(y_train)        \n",
    "        pr_s = cc\n",
    "        \n",
    "        prob_t = pred_prob.T        \n",
    "        prob_t_s = prob_t\n",
    "        \n",
    "        delta = 1\n",
    "        delta_s = 1\n",
    "        count = 0\n",
    "        \n",
    "        while delta>stop_delta and delta<=delta_s and count<500:\n",
    "            # E-step\n",
    "            for clss in range(len(cc)):\n",
    "                prob_t_s[clss] = prob_t[clss]*(pr_s[clss]/cc[clss]) \n",
    "            prob_t_s = normalize(prob_t_s, norm='l1',axis=0) \n",
    "            # M-step            \n",
    "            pr_s1=np.average(prob_t_s, axis=1)\n",
    "            delta_s=delta\n",
    "            delta=ae(pr_s,pr_s1)\n",
    "\n",
    "            pr_s=pr_s1\n",
    "            count=count+1\n",
    "            \n",
    "        pr_s = [pr_s[1],pr_s[0]]\n",
    "\n",
    "        if np.max(pr_s)>0.99:\n",
    "            pr_s=np.average(prob_t, axis=1)\n",
    "            pr_s = [pr_s[1],pr_s[0]]\n",
    "\n",
    "        return pr_s\n",
    "    \n",
    "def Iter1(X_test,clf, it = 10, stop_delta=0.00001):\n",
    "        pred_prev_train=CC(y_train)\n",
    "        pred_prev0=pred_prev_train.copy()\n",
    "\n",
    "        model = clf\n",
    "        model.fit(X_train_w2v, y_train)\n",
    "        pred_prev1=np.average(clf.predict_proba(X_test), axis=0)\n",
    "        \n",
    "        delta1=0\n",
    "        delta2=0\n",
    "        d_delta1=0\n",
    "        d_delta2=0\n",
    "        \n",
    "        for i in range(it):\n",
    "            class_weight=dict(zip([0,1], pred_prev1/pred_prev_train))\n",
    "\n",
    "            model=clf\n",
    "            model.fit(X_train_w2v, y_train)\n",
    "            pred_prev2=np.average(model.predict_proba(X_test), axis=0)\n",
    "            \n",
    "            delta1=delta2\n",
    "            delta2=ae(pred_prev1,pred_prev2)\n",
    "            d_delta3=abs(delta2-delta1)\n",
    "            if delta2<stop_delta or d_delta3>d_delta2 and d_delta2>d_delta1 and d_delta1!=0:\n",
    "                iter_model=model\n",
    "                break\n",
    "            d_delta1=d_delta2\n",
    "            d_delta2=d_delta3\n",
    "            \n",
    "            pred_prev0=pred_prev1.copy()\n",
    "            pred_prev1=pred_prev2.copy()\n",
    "    \n",
    "        iter_model=model\n",
    "        pred_prev1 = pred_prev1.tolist()\n",
    "        pred_prev1.reverse()\n",
    "        return pred_prev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getROC_Curve(pred,real):\n",
    "    fpr, tpr, thresholds = (roc_curve(pred,real))\n",
    "    return fpr[1],tpr[1]\n",
    "\n",
    "def get_positive_rate(X, y, k_fold = 5, clf = KNC(n_neighbors=7)):\n",
    "    fpr,tpr = 0,0\n",
    "    if type(y) != np.ndarray:\n",
    "        y = np.asarray(y)\n",
    "    kf = KFold(len(y), k_fold, shuffle=True, random_state=1)\n",
    "    for train, test in kf:\n",
    "#         print(np.asarray(X)[train])\n",
    "        X_train, X_test, y_train, y_test = np.asarray(X)[train,:].tolist(), np.asarray(X)[test,:].tolist(), y[train], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        n_fpr,n_tpr = getROC_Curve(clf.predict(X_test),y_test)\n",
    "        fpr += n_fpr\n",
    "        tpr += n_tpr\n",
    "    return fpr/k_fold,tpr/k_fold\n",
    "\n",
    "def get_exp_positive_rate(X, y, k_fold = 5, clf = KNC(n_neighbors=7)):    \n",
    "    et,ef = [],[]\n",
    "    if type(y) != np.ndarray:\n",
    "        y = np.asarray(y)\n",
    "    kf = KFold(len(y), k_fold, shuffle=True, random_state=1)\n",
    "    for train, test in kf:\n",
    "        efpr,etpr = 0,0\n",
    "        X_train, X_test, y_train, y_test = np.asarray(X)[train,:], np.asarray(X)[test,:], y[train], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        proba = clf.predict_proba(X_test)\n",
    "        \n",
    "        count_fpr = 0\n",
    "        for i,item in enumerate(y_test):\n",
    "            if item==0:\n",
    "                efpr += proba[i][0]\n",
    "                count_fpr += 1\n",
    "            elif item==1:\n",
    "                etpr +=proba[i][1]\n",
    "                \n",
    "        efpr = efpr/count_fpr\n",
    "        etpr = etpr/(len(y_test)-count_fpr)\n",
    "        \n",
    "        et.append(etpr),ef.append(efpr)\n",
    "    return np.average(ef),np.average(et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SemEval – 2016 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_preprocessing(tweet):\n",
    "    tweet = tweet.lower()        \n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)        \n",
    "    tweet = re.sub('@','',tweet)\n",
    "    tweet = re.sub('^[\\s]', '', tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)       \n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    tweet = \"\".join(word for word in tweet if word not in string.punctuation)    \n",
    "    tweet = tweet.split()    \n",
    "    numbers = re.compile(r'^[\\d]+.*')\n",
    "    tweet = [j for j in tweet if not numbers.search(j)]\n",
    "    tweet = ' '.join([x for x in tweet]) \n",
    "\n",
    "    return tweet    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv',sep='\\t', header=None)\n",
    "test_gold = pd.read_csv('data/test.csv',sep='\\t', header=None)\n",
    "tweets = []\n",
    "y = []\n",
    "topic =[]\n",
    "\n",
    "for i,tweet in enumerate(train[3]):\n",
    "    if tweet != 'Not Available':\n",
    "        tweet = tweet_preprocessing(tweet)           \n",
    "        \n",
    "        if train[2].values[i] == 'negative':\n",
    "            sem = 0\n",
    "        else:\n",
    "            sem = 1\n",
    "            \n",
    "        y.append(int(sem)),tweets.append(tweet),topic.append(train[1].values[i])\n",
    "       \n",
    "size = len(y)\n",
    "\n",
    "for i,tweet in enumerate(test_gold[3]):\n",
    "    if tweet != 'Not Available':\n",
    "        tweet = tweet_preprocessing(tweet)           \n",
    "        \n",
    "        if test_gold[2].values[i] == 'negative':\n",
    "            sem = 0\n",
    "        else:\n",
    "            sem = 1\n",
    "            \n",
    "        y.append(int(sem)),tweets.append(tweet),topic.append(test_gold[1].values[i])\n",
    "\n",
    "y_train = pd.Series(y[:size])\n",
    "y_test = pd.Series(y[size:])\n",
    "topic_train, topic_test = topic[:size], topic[size:]\n",
    "# print(len(y),len(y_train),len(y_test),topic[size:size+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer = \"word\",\n",
    "                           tokenizer = None,\n",
    "                           preprocessor = None,\n",
    "                           stop_words = 'english'\n",
    "                            )\n",
    "tf_idf = vectorizer.fit_transform(tweets)\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tf_idf, X_test_tf_idf = tf_idf[:size],tf_idf[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15221/15221 [04:35<00:00, 58.88it/s]\n"
     ]
    }
   ],
   "source": [
    "tweet_vec = []\n",
    "for i,sentence in (enumerate(tqdm(tweets))):\n",
    "    vec = [0]*300\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            vec += np.multiply(model[(word)],tf_idf[i].getcol(feature_names.index(word)).data[0])\n",
    "        except:\n",
    "            pass\n",
    "    tweet_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v = tweet_vec[:size],tweet_vec[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KLD and AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kld(p, q):\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    return np.sum(np.where(p != 0,p * np.log(p / q), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ae(p, q):\n",
    "        p = np.asarray(p, dtype=np.float)\n",
    "        q = np.asarray(q, dtype=np.float)\n",
    "        return np.average(np.abs(q-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = KNC(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and make prediction. ROC. Calculate (e)fpr, (e)tpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_w2v, y_train)\n",
    "predictions_w2v = clf.predict(X_test_w2v)\n",
    "prediction_proba_w2v = clf.predict_proba(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train_tf_idf, y_train)\n",
    "predictions_tf_idf = clf.predict(X_test_tf_idf)\n",
    "predictions_proba_tf_idf = clf.predict_proba(X_test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.792635665776\n"
     ]
    }
   ],
   "source": [
    "print('ROC:',roc_auc_score(y_test,predictions_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "fpr,tpr = get_positive_rate(X_train_w2v,y_train,clf=clf)\n",
    "efpr,etpr = get_exp_positive_rate(X_train_w2v,y_train,clf=clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification without division by topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "cc_real = CC(y_test)\n",
    "cc = CC(predictions_w2v)\n",
    "pcc = PCC(prediction_proba_w2v)\n",
    "acc = ACC(predictions_w2v,fpr,tpr)\n",
    "pacc = PACC(predictions_w2v,prediction_proba_w2v,efpr,etpr)\n",
    "em = EM(y_train,prediction_proba_w2v)\n",
    "iter1 = Iter1(X_test_w2v,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clf: LogisticRegression class_weight='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC: 0.0113330259922\n",
      "PCC: 0.0347102322248\n",
      "ACC: 0.341819977465\n",
      "PACC: 0.0347102322248\n",
      "EM: 0.2919045187\n",
      "Iter1 0.0347102322248\n"
     ]
    }
   ],
   "source": [
    "print('CC:',kld(cc_real,cc))\n",
    "print('PCC:',kld(cc_real,pcc))\n",
    "print('ACC:',kld(cc_real,acc))\n",
    "print('PACC:',kld(cc_real,pacc))\n",
    "print('EM:',kld(cc_real,em))\n",
    "print('Iter1',kld(cc_real,iter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clf: LogisticRegression without class_weight='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('CC:',kld(cc_real,cc))\n",
    "print('PCC:',kld(cc_real,pcc))\n",
    "print('ACC:',kld(cc_real,acc))\n",
    "print('PACC:',kld(cc_real,pacc))\n",
    "print('EM:',kld(cc_real,em))\n",
    "print('Iter1',kld(cc_real,iter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clf: KNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('CC:',kld(cc_real,cc))\n",
    "print('PCC:',kld(cc_real,pcc))\n",
    "print('ACC:',kld(cc_real,acc))\n",
    "print('PACC:',kld(cc_real,pacc))\n",
    "print('EM:',kld(cc_real,em))\n",
    "print('Iter1',kld(cc_real,iter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification with division by topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions_w2v\n",
    "proba = prediction_proba_w2v\n",
    "\n",
    "title_pred = []\n",
    "title_real = []\n",
    "title_proba = []\n",
    "\n",
    "uniq_title = []\n",
    "quant_list = []\n",
    "real_quant_list = []\n",
    "proba_quant_list = []\n",
    "\n",
    "title = topic_test[0]\n",
    "\n",
    "for i in range(len(topic_test)):\n",
    "    if topic_test[i] == title:\n",
    "        title_pred.append(predictions[i])\n",
    "        title_proba.append(proba[i])\n",
    "        title_real.append(y_test[i])\n",
    "        \n",
    "    else:\n",
    "        uniq_title.append(title)\n",
    "        title = topic_test[i]\n",
    "        \n",
    "        quant_list.append(title_pred)\n",
    "        real_quant_list.append(title_real)\n",
    "        proba_quant_list.append(title_proba)\n",
    "\n",
    "        \n",
    "        title_pred = []\n",
    "        title_proba = []\n",
    "        title_real = []\n",
    "        \n",
    "uniq_title.append(title)\n",
    "quant_list.append(title_pred)\n",
    "real_quant_list.append(title_real)      \n",
    "proba_quant_list.append(title_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  1%|          | 1/100 [00:01<02:15,  1.37s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  2%|▏         | 2/100 [00:02<02:10,  1.33s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  3%|▎         | 3/100 [00:03<02:02,  1.27s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  4%|▍         | 4/100 [00:04<01:58,  1.23s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  5%|▌         | 5/100 [00:06<02:02,  1.29s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  6%|▌         | 6/100 [00:07<02:04,  1.32s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  7%|▋         | 7/100 [00:09<02:11,  1.41s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  8%|▊         | 8/100 [00:10<02:15,  1.47s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "  9%|▉         | 9/100 [00:12<02:23,  1.57s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 10%|█         | 10/100 [00:14<02:21,  1.57s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 11%|█         | 11/100 [00:15<02:16,  1.53s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 12%|█▏        | 12/100 [00:16<02:04,  1.42s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 13%|█▎        | 13/100 [00:18<01:56,  1.34s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 14%|█▍        | 14/100 [00:19<01:55,  1.35s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 15%|█▌        | 15/100 [00:20<01:50,  1.31s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 16%|█▌        | 16/100 [00:21<01:45,  1.26s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 17%|█▋        | 17/100 [00:22<01:43,  1.25s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 18%|█▊        | 18/100 [00:24<01:41,  1.24s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 19%|█▉        | 19/100 [00:25<01:43,  1.27s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 20%|██        | 20/100 [00:26<01:44,  1.31s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 21%|██        | 21/100 [00:28<01:45,  1.34s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 22%|██▏       | 22/100 [00:29<01:44,  1.34s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 23%|██▎       | 23/100 [00:31<01:42,  1.33s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 24%|██▍       | 24/100 [00:32<01:41,  1.33s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 25%|██▌       | 25/100 [00:33<01:37,  1.30s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 26%|██▌       | 26/100 [00:34<01:36,  1.31s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 27%|██▋       | 27/100 [00:36<01:41,  1.40s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 28%|██▊       | 28/100 [00:38<01:48,  1.50s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 29%|██▉       | 29/100 [00:39<01:45,  1.49s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 30%|███       | 30/100 [00:41<01:48,  1.55s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 31%|███       | 31/100 [00:42<01:43,  1.50s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 32%|███▏      | 32/100 [00:44<01:37,  1.44s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 33%|███▎      | 33/100 [00:45<01:34,  1.41s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 34%|███▍      | 34/100 [00:46<01:30,  1.37s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 35%|███▌      | 35/100 [00:48<01:27,  1.35s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 36%|███▌      | 36/100 [00:49<01:25,  1.34s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 37%|███▋      | 37/100 [00:50<01:21,  1.30s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 38%|███▊      | 38/100 [00:51<01:17,  1.25s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 39%|███▉      | 39/100 [00:52<01:15,  1.24s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 40%|████      | 40/100 [00:53<01:11,  1.20s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 41%|████      | 41/100 [00:55<01:09,  1.18s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 42%|████▏     | 42/100 [00:56<01:06,  1.15s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 43%|████▎     | 43/100 [00:57<01:07,  1.18s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 44%|████▍     | 44/100 [00:58<01:04,  1.15s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 45%|████▌     | 45/100 [00:59<01:01,  1.12s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 46%|████▌     | 46/100 [01:00<01:01,  1.13s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 47%|████▋     | 47/100 [01:01<00:58,  1.11s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 48%|████▊     | 48/100 [01:02<00:58,  1.13s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 49%|████▉     | 49/100 [01:04<00:57,  1.12s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 50%|█████     | 50/100 [01:05<00:57,  1.15s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 51%|█████     | 51/100 [01:06<00:56,  1.16s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 52%|█████▏    | 52/100 [01:07<00:55,  1.16s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 53%|█████▎    | 53/100 [01:08<00:55,  1.18s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 54%|█████▍    | 54/100 [01:09<00:53,  1.16s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 55%|█████▌    | 55/100 [01:11<00:52,  1.16s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 56%|█████▌    | 56/100 [01:12<00:49,  1.13s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 57%|█████▋    | 57/100 [01:13<00:51,  1.21s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 58%|█████▊    | 58/100 [01:14<00:50,  1.21s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 59%|█████▉    | 59/100 [01:16<00:49,  1.21s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 60%|██████    | 60/100 [01:17<00:48,  1.22s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 61%|██████    | 61/100 [01:18<00:48,  1.25s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 62%|██████▏   | 62/100 [01:19<00:48,  1.28s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 63%|██████▎   | 63/100 [01:21<00:48,  1.30s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 64%|██████▍   | 64/100 [01:22<00:47,  1.31s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 65%|██████▌   | 65/100 [01:24<00:47,  1.35s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 66%|██████▌   | 66/100 [01:25<00:44,  1.32s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 67%|██████▋   | 67/100 [01:26<00:42,  1.30s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 68%|██████▊   | 68/100 [01:27<00:41,  1.30s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 69%|██████▉   | 69/100 [01:29<00:40,  1.32s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 70%|███████   | 70/100 [01:30<00:39,  1.30s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 71%|███████   | 71/100 [01:31<00:38,  1.32s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 72%|███████▏  | 72/100 [01:33<00:38,  1.36s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 73%|███████▎  | 73/100 [01:34<00:37,  1.37s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 74%|███████▍  | 74/100 [01:36<00:38,  1.48s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 75%|███████▌  | 75/100 [01:37<00:36,  1.47s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 76%|███████▌  | 76/100 [01:39<00:34,  1.44s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 77%|███████▋  | 77/100 [01:40<00:31,  1.39s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 78%|███████▊  | 78/100 [01:41<00:30,  1.40s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 79%|███████▉  | 79/100 [01:43<00:29,  1.41s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 80%|████████  | 80/100 [01:44<00:28,  1.43s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 81%|████████  | 81/100 [01:46<00:28,  1.49s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 82%|████████▏ | 82/100 [01:47<00:26,  1.46s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 83%|████████▎ | 83/100 [01:49<00:24,  1.46s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 84%|████████▍ | 84/100 [01:51<00:24,  1.53s/it]/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      " 85%|████████▌ | 85/100 [01:52<00:24,  1.62s/it]"
     ]
    }
   ],
   "source": [
    "aver_CC = []\n",
    "aver_PCC = []\n",
    "aver_ACC = []\n",
    "aver_PACC = []\n",
    "aver_EM = []\n",
    "aver_Iter1 = []\n",
    "it_start = 0\n",
    "it_stop = 0\n",
    "for i,lst in enumerate(tqdm(quant_list)):\n",
    "    it_stop += len(lst)\n",
    "    aver_CC.append(kld(CC(real_quant_list[i]),CC(lst)))\n",
    "    aver_PCC.append(kld(CC(real_quant_list[i]),PCC(np.array(proba_quant_list[i]))))\n",
    "    aver_ACC.append(kld(CC(real_quant_list[i]),ACC(lst,fpr,tpr)))\n",
    "    aver_PACC.append(kld(CC(real_quant_list[i]),PACC(lst,proba_quant_list[i],efpr,etpr)))\n",
    "    aver_EM.append(kld(CC(real_quant_list[i]),EM(y_train,np.array((proba_quant_list[i])))))\n",
    "    aver_Iter1.append(kld(CC(real_quant_list[i]),Iter1(X_test_w2v[it_start:it_stop],clf)))\n",
    "    it_start = it_stop\n",
    "    \n",
    "# print(np.average(),np.average(av_Iter1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('CC:',np.average(aver_CC))\n",
    "print('PCC:',np.average(aver_PCC))\n",
    "print('ACC:',np.average(aver_ACC))\n",
    "print('PACC:',np.average(aver_PACC))\n",
    "print('EM:',np.average(aver_EM))\n",
    "print('Iter1',np.average(aver_Iter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------ Comparison ------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/Arctickirillas/Rubrication/blob/master/quantification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import operator\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import normalize, Normalizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import metrics\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier as mc\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.mixture import GMM, VBGMM\n",
    "import os\n",
    "import scipy\n",
    "import random\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "class Quantification:\n",
    "    def __classificator(self, class_weight='auto'):\n",
    "        if class_weight=='':\n",
    "            #return SVC(kernel='rbf', probability=True)\n",
    "            return linear_model.LogisticRegression()\n",
    "            #return GMM(n_components=2)\n",
    "        else:\n",
    "            #return SVC(kernel='rbf', probability=True, class_weight = class_weight)\n",
    "            return linear_model.LogisticRegression(class_weight=class_weight)\n",
    "            #return GMM(n_components=2)\n",
    "\n",
    "    def __init__(self, method='', dir_name='temp', is_clean=True):\n",
    "        self.prefix='texts/'\n",
    "#         self.arff=Parse_ARFF()\n",
    "        self.dir_name=dir_name\n",
    "        if is_clean: self.__clean_dir(self.prefix+self.dir_name)\n",
    "        self.n_folds=5\n",
    "        self.classes=[0,1]\n",
    "        self.method_prev=self._bin_prevalence#._bin_prevalence or ._multi_prevalence\n",
    "        self.model=self.__classificator(class_weight='auto')\n",
    "        if method=='EM' or method=='EM1' or method=='Iter' or method=='Iter1':\n",
    "            self.method=method\n",
    "        elif method=='PCC' or method=='CC' or method=='ACC' or method=='PACC':\n",
    "            self.method=method\n",
    "        elif method=='test':\n",
    "            self.method=method\n",
    "            self._train_file, self._test_files=self.arff.read_dir(self.prefix+'pickle_'+dir_name)\n",
    "        elif method=='':\n",
    "            self.method='CC'\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(y, list): y=np.asarray(y)\n",
    "        self.classes=np.unique(y)\n",
    "        #if isinstance(y, csr_matrix):\n",
    "        #    self.y_train=y.toarray()\n",
    "        #elif isinstance(y, np.ndarray):\n",
    "        #    if len(y.shape)==1:\n",
    "        #        self.y_train=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y])\n",
    "        #    elif len(y.shape)==2:\n",
    "        #        self.y_train=y\n",
    "        self.y_train=y\n",
    "        self.X_train=X\n",
    "        self.model.fit(X, y)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, X, method=''):\n",
    "        if method!='':\n",
    "            self.method=method\n",
    "        if self.method=='CC':\n",
    "            y_pred=self.model.predict(X)\n",
    "            #print('CC', y_pred)\n",
    "            prevalence=self._classify_and_count(y_pred)\n",
    "        elif self.method=='ACC':\n",
    "            y_pred=self.model.predict(X)\n",
    "            self.kfold_results=self.__kfold_tp_fp(self.X_train, self.y_train, n_folds=self.n_folds)\n",
    "            prevalence=self._adj_classify_and_count(y_pred, is_prob=False)\n",
    "        elif self.method=='PCC':\n",
    "            prob_pred=self.model.predict_proba(X)\n",
    "            prevalence=self._prob_classify_and_count(prob_pred)\n",
    "        elif self.method=='PACC':\n",
    "            self.kfold_results=self.__kfold_prob_tp_fp(self.X_train, self.y_train, n_folds=self.n_folds)\n",
    "            prob_pred=self.model.predict_proba(X)\n",
    "            prevalence=self._adj_classify_and_count(prob_pred, is_prob=True)\n",
    "        elif self.method=='EM':\n",
    "            prob_pred=self.model.predict_proba(X)\n",
    "            prevalence=self._expectation_maximization(self.y_train, prob_pred, stop_delta=0.00001)\n",
    "        elif self.method=='EM1':\n",
    "            prob_pred=self.model.predict_proba(X)\n",
    "            prevalence=self._exp_max(self.y_train, prob_pred, stop_delta=0.00001)\n",
    "        elif self.method=='Iter':\n",
    "            prevalence=self._cost_sens_learning(X, stop_delta=0.00001, class_weight_start='auto')\n",
    "        elif self.method=='Iter1':\n",
    "            prevalence=self._cost_sens_learning(X, stop_delta=0.00001, class_weight_start='')\n",
    "        elif self.method=='test':\n",
    "            self._process_pipeline()\n",
    "        return prevalence\n",
    "\n",
    "    def predict_set(self, X_list, method=''):\n",
    "        scores=[]\n",
    "        for X in X_list:\n",
    "            prev_pred=self.predict(X,method)\n",
    "            scores.append(prev_pred)\n",
    "        return scores\n",
    "\n",
    "    def score(self, X_list, y_list, method=''):\n",
    "        scores=[]\n",
    "        for X, y in zip(X_list, y_list):\n",
    "            y=np.asarray(y)\n",
    "            prev_pred=self.predict(X,method)\n",
    "            prev_true=self._classify_and_count(y)\n",
    "            #print(prev_pred, prev_true)\n",
    "            #scores.append(self._divergence_bin(prev_true, prev_pred, self._kld))\n",
    "            scores.append(self._emd(prev_true, prev_pred))\n",
    "        return np.average(scores)\n",
    "\n",
    "    def make_drift_rnd(X,y,proportion=0.5):\n",
    "        index={}\n",
    "        for val in scipy.unique(y):\n",
    "            index[val]=[]\n",
    "        for key in range(len(y)):\n",
    "            index[y[key]].append(key)\n",
    "        ind2low=[]\n",
    "        num2low=int(len(index)/2)\n",
    "        while ind2low==[] and num2low!=0:\n",
    "            j=0\n",
    "            for i in index:\n",
    "                #print(i, j, num2low)\n",
    "                if j>=num2low:\n",
    "                    break\n",
    "                rnd=random.random()\n",
    "                #print(rnd,j,i)\n",
    "                if rnd<0.5:\n",
    "                    ind2low.append(i)\n",
    "                    j+=1\n",
    "        new_ind=index.copy()\n",
    "        new_set=[]\n",
    "        for ind in ind2low:\n",
    "            for val in index[ind]:\n",
    "                rnd=random.random()\n",
    "                if rnd > proportion:\n",
    "                    new_set.append(val)\n",
    "            new_ind[ind]=new_set\n",
    "        new_y=[]\n",
    "        new_X=[]\n",
    "\n",
    "        for i in index:\n",
    "            try:\n",
    "                new_y=np.concatenate((new_y,y[new_ind[i]]))\n",
    "                new_X=np.concatenate((new_X,X[new_ind[i]]),axis=0)\n",
    "            except:\n",
    "                new_y=y[new_ind[i]]\n",
    "                new_X=X[new_ind[i]]\n",
    "        return new_X, new_y\n",
    "\n",
    "    def make_drift_05(X,y,proportion=0.5):\n",
    "        #index=[]\n",
    "        #for key in range(len(scipy.unique(y))):\n",
    "        #    index.append(key)\n",
    "        #y=MultiLabelBinarizer(classes=index).fit_transform([[y_p] for y_p in y])\n",
    "        ind2low=[]\n",
    "        if proportion<0.5:\n",
    "            ind2low.append(0)\n",
    "            proportion=proportion*2\n",
    "        else:\n",
    "            ind2low=[i for i in range(1,y.shape[1])]\n",
    "            proportion=(1-proportion)*2\n",
    "\n",
    "        new_X=np.array([], ndmin=2)\n",
    "        new_y=np.array([], ndmin=2)\n",
    "        for clas in ind2low:\n",
    "            for ind, num in zip(y.transpose()[clas],range(len(y.transpose()[clas]))):\n",
    "                if ind>0.5:\n",
    "                    rnd=random.random()\n",
    "                    if rnd < proportion:\n",
    "                        if new_X!=np.array([], ndmin=2):\n",
    "                            #print(ind, rnd, new_y.shape,new_X.shape[0])\n",
    "                            tX=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                            new_X=np.concatenate((new_X,tX), axis=0)\n",
    "                            ty=np.ndarray(shape=(1,y[num].shape[0]), buffer=y[num].copy(), dtype=int)\n",
    "                            new_y=np.concatenate((new_y,ty), axis=0)\n",
    "                        else:\n",
    "                            new_X=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                            new_y=np.ndarray(shape=(1,y[num].shape[0]), buffer=y[num].copy(), dtype=int)\n",
    "                else:\n",
    "                    if new_X!=np.array([], ndmin=2):\n",
    "                        tX=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                        new_X=np.concatenate((new_X,tX), axis=0)\n",
    "                        ty=np.ndarray(shape=(1,y[num].shape[0]), buffer=y[num].copy(), dtype=int)\n",
    "                        new_y=np.concatenate((new_y,ty), axis=0)\n",
    "                    else:\n",
    "                        new_X=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                        new_y=np.ndarray(shape=(1,y[num].shape[0]), buffer=y[num].copy(), dtype=int)\n",
    "        return new_X, new_y\n",
    "\n",
    "    def make_drift_list(X,y,proportion=0.5):\n",
    "        #index=[]\n",
    "        #for key in range(len(scipy.unique(y))):\n",
    "        #    index.append(key)\n",
    "        #y=MultiLabelBinarizer(classes=index).fit_transform([[y_p] for y_p in y])\n",
    "        ind_set=scipy.unique(y)\n",
    "        if proportion<0.5:\n",
    "            ind2low=set([0])\n",
    "            proportion=proportion*2\n",
    "        else:\n",
    "            ind2low=set([i for i in range(1,len(ind_set))])\n",
    "            proportion=(1-proportion)*2\n",
    "\n",
    "        new_X=np.array([], ndmin=2)\n",
    "        new_y=[]\n",
    "        for clas in ind_set:\n",
    "            for ind, num in zip(y,range(len(y))):\n",
    "                if ind in ind2low:\n",
    "                    rnd=random.random()\n",
    "                    if rnd < proportion:\n",
    "                        if new_X!=np.array([], ndmin=2):\n",
    "                            tX=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                            new_X=np.concatenate((new_X,tX), axis=0)\n",
    "                            new_y.append(ind)\n",
    "                        else:\n",
    "                            new_X=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                            new_y.append(ind)\n",
    "                else:\n",
    "                    if new_X!=np.array([], ndmin=2):\n",
    "                        tX=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                        new_X=np.concatenate((new_X,tX), axis=0)\n",
    "                        new_y.append(ind)\n",
    "                    else:\n",
    "                        new_X=np.ndarray(shape=(1,X[num].shape[0]), buffer=X[num].copy())\n",
    "                        new_y.append(ind)\n",
    "        return new_X, new_y\n",
    "\n",
    "    def _kld(self, p, q):\n",
    "        \"\"\"Kullback-Leibler divergence D(P || Q) for discrete distributions when Q is used to approximate P\n",
    "        Parameters\n",
    "        p, q : array-like, dtype=float, shape=n\n",
    "        Discrete probability distributions.\"\"\"\n",
    "        p = np.asarray(p, dtype=np.float)\n",
    "        q = np.asarray(q, dtype=np.float)\n",
    "        return np.sum(np.where(p != 0,p * np.log(p / q), 0))\n",
    "\n",
    "    def _rae(self, p, q):\n",
    "        p = np.asarray(p, dtype=np.float)\n",
    "        q = np.asarray(q, dtype=np.float)\n",
    "        return np.sum(np.where(p != 0,np.abs(q-p)/p, 0))\n",
    "\n",
    "    def _ae(self, p, q):\n",
    "        #Absolute error\n",
    "        p = np.asarray(p, dtype=np.float)\n",
    "        q = np.asarray(q, dtype=np.float)\n",
    "        return np.average(np.abs(q-p))\n",
    "\n",
    "    def _emd(self,p,q):\n",
    "        #Earth Mover’s Distance (Rubner et al., 2000)\n",
    "        p = np.asarray(p, dtype=np.float)\n",
    "        q = np.asarray(q, dtype=np.float)\n",
    "        emd=0\n",
    "        for i in range(1,len(p)):\n",
    "            #emd+=np.abs(np.sum(q[0:i])-np.sum(p[0:i]))\n",
    "            emd+=np.sum(np.abs(q[0:i]-p[0:i]))\n",
    "        return emd\n",
    "\n",
    "    def _divergence_bin(self,p,q,func=''):\n",
    "        if func=='':func=self._kld\n",
    "        p = np.asarray(p, dtype=np.float)\n",
    "        q = np.asarray(q, dtype=np.float)\n",
    "        #print(p,q)\n",
    "        klds=[]\n",
    "        for p_i,q_i in zip(p,q):\n",
    "            klds.append(func([p_i,1-p_i], [q_i,1-q_i]))\n",
    "        #print(len(_klds))\n",
    "        #_avg=np.average(_klds)\n",
    "        return klds#_avg\n",
    "\n",
    "    def _multi_prevalence(self, y):\n",
    "        prevalence=[]\n",
    "        prevalence_smooth=[]\n",
    "        eps=1/(2*y.shape[0])\n",
    "        if isinstance(y,csr_matrix):\n",
    "            for _col in range(y.shape[1]):\n",
    "                prevalence.append(y.getcol(_col).nnz)\n",
    "            prevalence=prevalence/(np.sum(prevalence))\n",
    "            for _val in prevalence: # perform smoothing\n",
    "                prevalence_smooth.append(_val+eps)\n",
    "            prevalence_smooth=prevalence_smooth/(np.sum(prevalence)+eps*y.shape[1])\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            if len(y.shape)==1:\n",
    "                yt=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y]).transpose()\n",
    "                for col in yt:\n",
    "                    prevalence.append(np.sum(col))\n",
    "                prevalence=prevalence/(np.sum(prevalence))\n",
    "                for val in prevalence: # perform smoothing\n",
    "                    prevalence_smooth.append(val+eps)\n",
    "                prevalence_smooth=prevalence_smooth/(np.sum(prevalence)+eps*yt.shape[0])\n",
    "            elif len(y.shape)==2:\n",
    "                yt=y.transpose()\n",
    "                for col in yt:\n",
    "                    prevalence.append(np.sum(col))\n",
    "                prevalence=prevalence/(np.sum(prevalence))\n",
    "                for val in prevalence: # perform smoothing\n",
    "                    prevalence_smooth.append(val+eps)\n",
    "                prevalence_smooth=prevalence_smooth/(np.sum(prevalence)+eps*yt.shape[0])\n",
    "        return prevalence_smooth\n",
    "\n",
    "    def _bin_prevalence(self, y):\n",
    "        prevalence=[]\n",
    "        if isinstance(y,csr_matrix):\n",
    "            eps=1/(2*y.shape[0])\n",
    "            for col in range(y.shape[1]):\n",
    "                prevalence.append((y.getcol(col).nnz+eps)/(eps*y.shape[1]+y.shape[0]))\n",
    "            prevalence=np.asarray(prevalence, dtype=np.float)\n",
    "        elif isinstance(y,list):\n",
    "            eps=1/(2*len(y))\n",
    "            yt=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y]).transpose()\n",
    "            for col in range(yt.shape[0]):\n",
    "                prevalence.append((np.sum(yt[col])+eps)/(eps*yt.shape[0]+yt.shape[1]))\n",
    "            prevalence=np.asarray(prevalence, dtype=np.float)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            eps=1/(2*y.shape[0])\n",
    "            if len(y.shape)==1:\n",
    "                #print(self.classes, 'Variable \"y\" should have more then 1 dimension. Use MultiLabelBinarizer()')\n",
    "                yt=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y]).transpose()\n",
    "            elif len(y.shape)==2:\n",
    "                yt=y.transpose()\n",
    "            for col in range(yt.shape[0]):\n",
    "                prevalence.append((np.sum(yt[col])+eps)/(eps*yt.shape[0]+yt.shape[1]))\n",
    "            prevalence=np.asarray(prevalence, dtype=np.float)\n",
    "        return prevalence\n",
    "\n",
    "    def _bin_prevalence_prob(self, y):\n",
    "        y = np.asarray(y, dtype=np.float).T\n",
    "        eps=1/(2*y.shape[1])\n",
    "        prevalence=[]\n",
    "        print(self.model.intercept_[0][0], self.model.coef_)\n",
    "        for col in y:\n",
    "            nnz=0\n",
    "            for elem in col:\n",
    "                if elem>=self.model.intercept_:\n",
    "                    nnz+=1\n",
    "            prevalence.append((nnz+eps)/(eps*y.shape[0]+y.shape[1]))\n",
    "        return prevalence\n",
    "\n",
    "    def __clean_dir(self, dir):\n",
    "        for name in os.listdir(dir):\n",
    "            file = os.path.join(dir, name)\n",
    "            if not os.path.islink(file) and not os.path.isdir(file):\n",
    "                os.remove(file)\n",
    "\n",
    "    def __split_by_prevalence(self):\n",
    "        [csr, y, y_names]=self._read_pickle(self._train_file)\n",
    "        _prevalence=self.method_prev(y)\n",
    "        ly=y.shape[1]\n",
    "        _VLP=[]\n",
    "        _LP=[]\n",
    "        _HP=[]\n",
    "        _VHP=[]\n",
    "        _col=0\n",
    "        for _val in _prevalence:\n",
    "            if _val < 0.01:\n",
    "                for _i in range(4):\n",
    "                    _VLP.append(_col+ly*_i)\n",
    "            elif _val>=0.01 and _val<0.05:\n",
    "                for _i in range(4):\n",
    "                    _LP.append(_col+ly*_i)\n",
    "            elif _val>=0.05 and _val<0.1:\n",
    "                for _i in range(4):\n",
    "                    _HP.append(_col+ly*_i)\n",
    "            elif _val>=0.1:\n",
    "                for _i in range(4):\n",
    "                    _VHP.append(_col+ly*_i)\n",
    "            _col+=1\n",
    "        return [0, _VLP, _LP, _HP, _VHP]\n",
    "\n",
    "    def __split_by_distribution_drift(self):#pickle_QuantRCV1\n",
    "        [csr, y, y_names]=self._read_pickle(self._train_file)\n",
    "        pr_train=self.method_prev(y)\n",
    "        _arrange=[]\n",
    "        j=0\n",
    "        for _test_file in self._test_files:\n",
    "            [csr1, y1, y1_names] = self._read_pickle(_test_file)\n",
    "            pr_test=self.method_prev(y1)\n",
    "            #_arrange.append((_j,self.kld_bin(pr_test, pr_train)))\n",
    "            for _i in range(len(pr_train)):\n",
    "                _arrange.append((j, self._kld([pr_test[_i], 1-pr_test[_i]], [pr_train[_i], 1-pr_train[_i]])))\n",
    "                j=j+1\n",
    "        _arrange_sorted=sorted(_arrange, key=operator.itemgetter(1))\n",
    "        _VLD=[_x[0] for _x in _arrange_sorted[:len(y_names)]]\n",
    "        _LD=[_x[0] for _x in _arrange_sorted[len(y_names):2*len(y_names)]]\n",
    "        _HD=[_x[0] for _x in _arrange_sorted[2*len(y_names):3*len(y_names)]]\n",
    "        _VHD=[_x[0] for _x in _arrange_sorted[3*len(y_names):]]\n",
    "        return [_arrange, _VLD, _LD, _HD, _VHD]\n",
    "\n",
    "    def _read_pickle(self, file):\n",
    "        print('Read file '+file)\n",
    "        with open(file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            f.close()\n",
    "        return data\n",
    "\n",
    "    def _estimate_cl_indexes(self):#pickle_QuantRCV1\n",
    "        #[_csr, _y, y_names]=self._read_pickle(self._train_file)\n",
    "        #_prev_train=self.count_prevalence(_y)\n",
    "        #model=self.arff.fit(_csr,_y)\n",
    "        _pr_list=[]\n",
    "        _y1_list=[]\n",
    "        for _test_file in self._test_files:\n",
    "            [_csr1, _y1, _y1_names] = self._read_pickle(_test_file)\n",
    "            _y1_list.append(_y1)\n",
    "            _pr_list.append(self.model.predict(_csr1))\n",
    "        with open(self.prefix+'cl_indexes_'+self.dir_name+'.pickle', 'wb') as f:\n",
    "            print(self.prefix+'cl_indexes_'+self.dir_name+'.pickle')\n",
    "            pickle.dump([_y, _y1_list, _pr_list, _test_files, y_names], f)\n",
    "            f.close()\n",
    "        names_ = [_y, _y1_list, _pr_list, _test_files, y_names]\n",
    "        return names_\n",
    "\n",
    "    def __subset(self, _inp_set, _indexes):\n",
    "        _sub_set=[]\n",
    "        for _i in _indexes:\n",
    "            _sub_set.append(_inp_set[_i])\n",
    "        #_sub_set=_sub_set/np.sum(_sub_set)\n",
    "        return _sub_set\n",
    "\n",
    "    def __count_splited_KLD(self, _part, _prev_test, _prev_test_estimate):\n",
    "        split_by=[np.average(self._divergence_bin(self.__subset(_prev_test,_part[1]), self.__subset(_prev_test_estimate,_part[1]))),\n",
    "        np.average(self._divergence_bin(self.__subset(_prev_test,_part[2]), self.__subset(_prev_test_estimate,_part[2]))),\n",
    "        np.average(self._divergence_bin(self.__subset(_prev_test,_part[3]), self.__subset(_prev_test_estimate,_part[3]))),\n",
    "        np.average(self._divergence_bin(self.__subset(_prev_test,_part[4]), self.__subset(_prev_test_estimate,_part[4]))),\n",
    "        np.average(self._divergence_bin(_prev_test, _prev_test_estimate))]\n",
    "        return split_by\n",
    "\n",
    "    def __count_ttest(self, _prev_test, _prev_test_estimate1, _prev_test_estimate2):\n",
    "        _kld_1=self._divergence_bin(_prev_test, _prev_test_estimate1)\n",
    "        _kld_2=self._divergence_bin(_prev_test, _prev_test_estimate2)\n",
    "        tt=stats.ttest_rel(_kld_1, _kld_2)\n",
    "        return tt\n",
    "\n",
    "    def _classify_and_count(self, _y_test):\n",
    "        #_prev_test=[]\n",
    "        #for _y_test in y_list:# Test files loop\n",
    "        #    if is_prob:\n",
    "        #        _prev_test=np.concatenate((_prev_test,self.method_prev(_y_test)), axis=1)\n",
    "        #    else:\n",
    "        #        _prev_test=np.concatenate((_prev_test,self.method_prev(_y_test)), axis=1)\n",
    "        _prev_test=self.method_prev(_y_test)\n",
    "        return _prev_test\n",
    "\n",
    "    def _count_diff1(self, _prev_test, _prev_test_estimate, _num_iter):\n",
    "        _parts_P=self.__split_by_prevalence()\n",
    "        _parts_D=self.__split_by_distribution_drift()\n",
    "        kld_bin=self._divergence_bin(_prev_test, _prev_test_estimate)\n",
    "        print('\\t\\t\\t VLP \\t\\t\\t LP \\t\\t\\t HP \\t\\t\\t VHP \\t\\t\\t total')\n",
    "        print(np.average(self.__subset(kld_bin, _parts_P[1])), np.average(self.__subset(kld_bin,_parts_P[2])),\\\n",
    "        np.average(self.__subset(kld_bin,_parts_P[3])), np.average(self.__subset(kld_bin,_parts_P[4])), np.average(kld_bin))\n",
    "        print('\\t\\t\\t VLD \\t\\t\\t LD \\t\\t\\t HD \\t\\t\\t VHD \\t\\t\\t total')\n",
    "        print(np.average(self.__subset(kld_bin, _parts_D[1])), np.average(self.__subset(kld_bin,_parts_D[2])),\\\n",
    "        np.average(self.__subset(kld_bin,_parts_D[3])), np.average(self.__subset(kld_bin,_parts_D[4])), np.average(kld_bin))\n",
    "        print('\\t\\t\\t VLP \\t\\t\\t LP \\t\\t\\t HP \\t\\t\\t VHP \\t\\t\\t total')\n",
    "        print(np.average(self.__subset(_num_iter, _parts_P[1])), np.average(self.__subset(_num_iter,_parts_P[2])),\\\n",
    "        np.average(self.__subset(_num_iter,_parts_P[3])), np.average(self.__subset(_num_iter,_parts_P[4])), np.average(_num_iter))\n",
    "        print('\\t\\t\\t VLD \\t\\t\\t LD \\t\\t\\t HD \\t\\t\\t VHD \\t\\t\\t total')\n",
    "        print(np.average(self.__subset(_num_iter, _parts_D[1])), np.average(self.__subset(_num_iter,_parts_D[2])),\\\n",
    "        np.average(self.__subset(_num_iter,_parts_D[3])), np.average(self.__subset(_num_iter,_parts_D[4])), np.average(_num_iter))\n",
    "        return 0\n",
    "\n",
    "    def _count_diff(self, _prev_test, _prev_test_estimate):\n",
    "        _parts_D=self.__split_by_distribution_drift()\n",
    "        _parts_P=self.__split_by_prevalence()\n",
    "        #print(len(_parts_P[1]),len(_parts_P[2]),len(_parts_P[3]),len(_parts_P[4]))\n",
    "        _kld_P=self.__count_splited_KLD(_parts_P, _prev_test, _prev_test_estimate)\n",
    "        print('\\t\\t\\t\\t VLP \\t\\t\\t\\t LP \\t\\t\\t\\t HP \\t\\t\\t\\t VHP \\t\\t\\t\\t total \\n', _kld_P)\n",
    "        _kld_D=self.__count_splited_KLD(_parts_D, _prev_test, _prev_test_estimate)\n",
    "        print('\\t\\t\\t\\t VLD \\t\\t\\t\\t LD \\t\\t\\t\\t HD \\t\\t\\t\\t VHD \\t\\t\\t\\t total \\n', _kld_D)\n",
    "        return _kld_P[4]\n",
    "\n",
    "    def _unite_cl_prob(self):\n",
    "        #read probabilities from separate files and aggregate it to one file\n",
    "        [_csr, _y, y_names]=self._read_pickle(self._train_file)\n",
    "        _train_file, _test_files=self.arff.read_dir(self.prefix+'cl_prob_'+self.dir_name)\n",
    "        _prob_list=[]\n",
    "        for _test_file in _test_files:\n",
    "            with open(_test_file, 'rb') as f:\n",
    "                _prob = pickle.load(f)\n",
    "                f.close()\n",
    "            _prob_list.append(_prob)\n",
    "        _y1_list=[]\n",
    "        for _test_file1 in self._test_files:\n",
    "            [_csr1, _y1, _y1_names] = self._read_pickle(_test_file1)\n",
    "            _y1_list.append(_y1)\n",
    "        with open('texts/cl_prob_'+self.dir_name+'.pickle', 'wb') as f:\n",
    "            pickle.dump([_y, _y1_list, _prob_list, self._test_files, _y1_names], f)\n",
    "            f.close()\n",
    "        return [_y, _y1_list, _prob_list, self._test_files, _y1_names]\n",
    "\n",
    "    def _estimate_cl_prob(self):\n",
    "        try:\n",
    "            with open('texts/ml_model_'+self.dir_name+'.pickle', 'rb') as f:\n",
    "                self.model = pickle.load(f)\n",
    "                f.close()\n",
    "        except:\n",
    "            [_csr, _y, y_names]=self._read_pickle(self._train_file)\n",
    "            _prev_train=self.count_prevalence(_y)\n",
    "            model=self.model#self.arff.fit(_csr,_y)\n",
    "            with open('texts/ml_model_'+self.dir_name+'.pickle', 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "                f.close()\n",
    "\n",
    "        _prob_list=[]\n",
    "        _y1_list=[]\n",
    "        for _t in range(len(self._test_files)):# range(42,52):\n",
    "            _test_file=self._test_files[_t]\n",
    "            [_csr1, _y1, _y1_names] = self._read_pickle(_test_file)\n",
    "            _y1_list.append(_y1)\n",
    "            _prob=model.predict_proba(_csr1)\n",
    "            _prob_list.append(_prob)\n",
    "            with open('texts/cl_prob_'+_test_file.rstrip('.arff.pickle').lstrip('texts/pickle_')+'.cl_prob', 'wb') as f:\n",
    "                pickle.dump(_prob, f)\n",
    "                f.close()\n",
    "        with open('texts/cl_prob_'+self.dir_name+'.pickle', 'wb') as f:\n",
    "            pickle.dump([_y, _y1_list, _prob_list, self._test_files, _y1_names], f)\n",
    "            f.close()\n",
    "        return [_y, _y1_list, _prob_list, self._test_files, y_names]\n",
    "\n",
    "    def _prob_classify_and_count(self, pred_prob):\n",
    "        #avr_prob=[]\n",
    "        #for pred_prob in pred_prob_list:\n",
    "        #    avr_prob=np.concatenate((avr_prob,np.average(pred_prob, axis=0)))\n",
    "        #print('PCC',avr_prob)\n",
    "        return np.average(pred_prob, axis=0)\n",
    "\n",
    "    def _exp_max(self, y_train, pred_prob, stop_delta=0.1):\n",
    "        pr_train=self._bin_prevalence(y_train)\n",
    "        pr_all=[]\n",
    "        pr_s=pr_train.copy()\n",
    "        prob_t=pred_prob.T\n",
    "        prob_t_s =prob_t.copy()\n",
    "        delta=1\n",
    "        delta_s=1\n",
    "        count=0\n",
    "        while delta>stop_delta and delta<=delta_s and count<100:\n",
    "            for cl_n in range(len(pr_train)):#Category\n",
    "                prob_t_s[cl_n]=prob_t[cl_n].copy()*(pr_s[cl_n]/pr_train[cl_n])  #E step\n",
    "            prob_t_s=normalize(prob_t_s, norm='l1',axis=0)                      #E step\n",
    "            pr_s1=np.average(prob_t_s, axis=1)                                  #M step\n",
    "            #pr_s1=self._adj_classify_and_count([prob_t_s.transpose()],is_prob=True)\n",
    "            delta_s=delta\n",
    "            #delta=np.max(np.abs(pr_s1-pr_s))\n",
    "            delta=self._ae(pr_s,pr_s1)\n",
    "            #print('pr_s1',pr_s1, delta)\n",
    "            #print(prob_t_s)\n",
    "            #pr_train=pr_s.copy()\n",
    "            #prob_t=prob_t_s.copy()\n",
    "            pr_s=pr_s1.copy()\n",
    "            count=count+1\n",
    "        if np.max(pr_s)>0.99: pr_s=np.average(prob_t, axis=1)\n",
    "        return pr_s\n",
    "\n",
    "    def _expectation_maximization(self, y_train, pred_prob, stop_delta=0.1):#_indexes\n",
    "        #[y_train, y_test_list, pred_prob_list, test_files, y_names]=_indexes\n",
    "        #print(pred_prob_list[0][1])\n",
    "        pr_train=self._bin_prevalence(y_train)\n",
    "        pr_all=[]\n",
    "        num_iter=[]\n",
    "        test_num=0#0..3 len(_y_test_list)\n",
    "        pr_c=pr_train.copy()\n",
    "\n",
    "        prob=pred_prob.T\n",
    "        for cl_n in range(len(pr_train)):#Category\n",
    "            #print('Test set N %s, class number %s' %(test_num, cl_n))\n",
    "            iter=0\n",
    "            _delta=1\n",
    "            while _delta>stop_delta:\n",
    "                pr_c_x=[]\n",
    "                _j=0\n",
    "                for pr_c_xk in prob[cl_n]:#xk in category c\n",
    "            #Step E\n",
    "                    pr_c_x_k=(pr_c[cl_n]/pr_train[cl_n]*pr_c_xk)/(((1-pr_c[cl_n])/(1-pr_train[cl_n]))*(1-pr_c_xk)+pr_c[cl_n]/pr_train[cl_n]*pr_c_xk)\n",
    "                    pr_c_x.append(pr_c_x_k)\n",
    "                    _j+=1\n",
    "            #Step M\n",
    "                pr_c_new=np.average(pr_c_x)#np.average(_prob[cl_n])\n",
    "                _delta=np.abs(pr_c_new-pr_c[cl_n])\n",
    "                #print('_delta',_delta)\n",
    "                #pr_train[cl_n]=pr_c[cl_n]\n",
    "                #prob[cl_n]=pr_c_x_k\n",
    "                pr_c[cl_n]=pr_c_new\n",
    "                iter+= 1\n",
    "            num_iter.append(iter)\n",
    "            if np.max([pr_c[cl_n],1-pr_c[cl_n]])>0.99: pr_c[cl_n]=np.average(prob[cl_n])\n",
    "        return pr_c #,num_iter\n",
    "\n",
    "    def _cost_sens_learning(self, X_test, stop_delta=0.00001, class_weight_start='auto'):\n",
    "        pred_prev_train=CC(self.y_train)\n",
    "        pred_prev_train.reverse()\n",
    "        pred_prev0=pred_prev_train.copy()\n",
    "        model=self.__classificator(class_weight=class_weight_start)#class_weight={0:1,1:1})##\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        pred_prev1=np.average(model.predict_proba(X_test), axis=0)#\n",
    "        #pred_prev1=self._classify_and_count(model.predict(X_test))\n",
    "        delta1=0\n",
    "        delta2=0\n",
    "        d_delta1=0\n",
    "        d_delta2=0\n",
    "        for i in range(10):\n",
    "            #print('pred_prev0',pred_prev0)\n",
    "            #print('pred_prev1',pred_prev1)\n",
    "            #print(pred_prev1/pred_prev_train)\n",
    "            #print(delta2)\n",
    "            \n",
    "            class_weight=dict(zip(self.classes, pred_prev1/pred_prev_train))\n",
    "\n",
    "\n",
    "            model=self.__classificator(class_weight=class_weight)\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            pred_prev2=np.average(model.predict_proba(X_test), axis=0)#\n",
    "            #pred_prev2=self._classify_and_count(model.predict(X_test))#\n",
    "            delta1=delta2\n",
    "            delta2=self._ae(pred_prev1,pred_prev2)\n",
    "            d_delta3=abs(delta2-delta1)\n",
    "            if delta2<stop_delta or d_delta3>d_delta2 and d_delta2>d_delta1 and d_delta1!=0:\n",
    "                #print('dd',d_delta1, d_delta2,d_delta3)\n",
    "                self.iter_model=model\n",
    "                break\n",
    "            d_delta1=d_delta2\n",
    "            d_delta2=d_delta3\n",
    "            #print(pred_prev2[0],'\\t', delta1)\n",
    "            #if delta2<stop_delta:\n",
    "            #    break\n",
    "            pred_prev0=pred_prev1.copy()\n",
    "            pred_prev1=pred_prev2.copy()\n",
    "        #print('pred_prev1',pred_prev1)\n",
    "        self.iter_model=model\n",
    "        return pred_prev1\n",
    "\n",
    "    def __conditional_probability(self,p1,p2,val1,val2):\n",
    "        c=0\n",
    "        for _i in range(len(p1)):\n",
    "            if p1[_i]==val1 and p2[_i]==val2:\n",
    "                c=c+1\n",
    "        return c/len(p1)\n",
    "\n",
    "    def __kfold_tp_fp(self, X, y, n_folds=2):\n",
    "        #return true positive rate and false positive rate arrays\n",
    "\n",
    "        #if isinstance(X, csr_matrix) and isinstance(y, csr_matrix):\n",
    "        #    X=X.toarray()\n",
    "        #    y=y.toarray()\n",
    "        #elif isinstance(X, csr_matrix) and isinstance(y, np.ndarray):\n",
    "        #    X=X.toarray()\n",
    "        #    y=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y])\n",
    "        #elif isinstance(X, np.ndarray) and isinstance(y, np.ndarray):\n",
    "        #    if len(y.shape)==1:\n",
    "        #        y=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y])\n",
    "        #    elif len(y.shape)==2:\n",
    "        #        pass\n",
    "        if isinstance(y, list):\n",
    "            y=np.asarray(y)\n",
    "\n",
    "        try:\n",
    "            with open(self.prefix+self.dir_name+'/'+str(n_folds)+'FCV.pickle', 'rb') as f:\n",
    "                [tp_av, fp_av] = pickle.load(f)\n",
    "        except:\n",
    "            _kf=KFold(y.shape[0],n_folds=n_folds)\n",
    "            tp=[]\n",
    "            fp=[]\n",
    "            for train_index, test_index in _kf:\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                model=self.model\n",
    "                model=model.fit(X_train, y_train)#arff.fit(X_train, y_train)\n",
    "                y_predict=model.predict(X_test)\n",
    "                tp_k=[]\n",
    "                fp_k=[]\n",
    "                if len(y.shape)==1:\n",
    "                    y_test=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y_test])\n",
    "                    y_predict=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y_predict])\n",
    "                elif len(y.shape)==2:\n",
    "                    pass\n",
    "                for s_true,s_pred in zip(y_test.T,y_predict.T):\n",
    "                    tp_k.append(self.__conditional_probability(s_pred, s_true, 1., 1.))#cm[0,0]/len(s_true))\n",
    "                    fp_k.append(self.__conditional_probability(s_pred, s_true, 1., 0.))#cm[1,0]/len(s_true))#len(s_true))\n",
    "                tp.append(tp_k)\n",
    "                fp.append(fp_k)\n",
    "            tp_av=np.asarray([np.average(tp_k) for tp_k in np.asarray(tp).T])\n",
    "            fp_av=np.asarray([np.average(fp_k) for fp_k in np.asarray(fp).T])\n",
    "            with open(self.prefix+self.dir_name+'/'+str(n_folds)+'FCV.pickle', 'wb') as f:\n",
    "                pickle.dump([tp_av, fp_av], f)\n",
    "                f.close()\n",
    "            #print('[tp_av, fp_av] by index',tp_av, fp_av)\n",
    "        return [tp_av, fp_av]\n",
    "\n",
    "    def __kfold_prob_tp_fp(self, X, y, n_folds=2):\n",
    "        # if isinstance(X, csr_matrix) and isinstance(y, np.ndarray):\n",
    "        #     X=X.toarray()\n",
    "        # elif isinstance(X, np.ndarray) and isinstance(y, np.ndarray):\n",
    "        #     if len(y.shape)==1:\n",
    "        #         y=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y])\n",
    "        #     elif len(y.shape)==2:\n",
    "        #         pass\n",
    "        if isinstance(y, list):\n",
    "            y=np.asarray(y)\n",
    "\n",
    "        try:\n",
    "            with open(self.prefix+self.dir_name+'/'+str(n_folds)+'FCV_prob.pickle', 'rb') as f:\n",
    "                [tp_av, fp_av] = pickle.load(f)\n",
    "        except:\n",
    "            kf=KFold(y.shape[0],n_folds=n_folds)\n",
    "            TP_avr=[]\n",
    "            FP_avr=[]\n",
    "            for train_index, test_index in kf:\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                model=self.model\n",
    "                model=model.fit(X_train, y_train)\n",
    "                y_predict=model.predict(X_test)\n",
    "                y_prob_predict=model.predict_proba(X_test)\n",
    "                TP=[]\n",
    "                FP=[]\n",
    "                if len(y.shape)==1:\n",
    "                    y_predict=MultiLabelBinarizer(classes=self.classes).fit_transform([[y_p] for y_p in y_predict])\n",
    "                elif len(y.shape)==2:\n",
    "                    pass\n",
    "                for class_ind, class_prob in zip(y_predict.transpose(), y_prob_predict.transpose()):\n",
    "                    TP_class=[]\n",
    "                    FP_class=[]\n",
    "                    for ind, prob in zip(class_ind, class_prob):\n",
    "                        if ind==1: TP_class.append(prob)\n",
    "                        elif ind==0: FP_class.append(prob)\n",
    "                    TP.append(np.sum(TP_class)/len(class_ind))\n",
    "                    FP.append(np.sum(FP_class)/len(class_ind))\n",
    "                TP_avr.append(TP)\n",
    "                FP_avr.append(FP)\n",
    "            tp_av, fp_av=np.average(TP_avr, axis=0), np.average(FP_avr, axis=0)\n",
    "            with open(self.prefix+self.dir_name+'/'+str(n_folds)+'FCV_prob.pickle', 'wb') as f:\n",
    "                pickle.dump([tp_av, fp_av], f)\n",
    "                f.close()\n",
    "            #print('tp, fp by prob', tp_av, fp_av)\n",
    "        return [tp_av, fp_av]\n",
    "\n",
    "    def _adj_classify_and_count(self, y_pred, is_prob=False):\n",
    "        [tp_av, fp_av]=self.kfold_results\n",
    "\n",
    "        if is_prob:\n",
    "            pr=np.average(y_pred,axis=0)\n",
    "        else:\n",
    "            pr=self.method_prev(y_pred)\n",
    "        try:\n",
    "            pred=(pr-fp_av)/(tp_av-fp_av)\n",
    "            if np.min(pred)>=0:\n",
    "                pred=normalize(pred, norm='l1', axis=1)[0]\n",
    "            else:\n",
    "                #print(pred)\n",
    "                #print(pr,tp_av,fp_av)\n",
    "                pred=pr\n",
    "        except:\n",
    "            print(pr,tp_av,fp_av)\n",
    "            pred=pr\n",
    "        return pred\n",
    "\n",
    "    def _process_pipeline(self):\n",
    "        #Warning! Processing can takes a long period. We recommend to perform it step by step\n",
    "        #pa=Parse_ARFF()\n",
    "        #pa.convert_arff(QuantOHSUMED, is_predict=False)\n",
    "        #q=Quantification('QuantOHSUMED')\n",
    "        #q.process_pipeline()\n",
    "        #####################################################\n",
    "        [self.X_train, self.y_train, y_names]=self._read_pickle(self._train_file)\n",
    "        self.fit(self.X_train, self.y_train)\n",
    "        #[y_train, y_test_list, y_pred_list, test_files, y_names]=self._estimate_cl_indexes()\n",
    "        [y_train,y_test_list,y_pred_list,test_files, y_names]=self._read_pickle('texts/cl_indexes_'+self.dir_name+'.pickle')\n",
    "        td=self._classify_and_count(y_test_list)\n",
    "        ed1=self._classify_and_count(y_pred_list)\n",
    "\n",
    "        ed2=self._adj_classify_and_count(self.X_train, self.y_train, y_pred_list)\n",
    "\n",
    "        self._estimate_cl_prob()\n",
    "        self._unite_cl_prob()\n",
    "        [y_train,y_test_list,pred_prob_list,test_files, y_names]=self._read_pickle('texts/cl_prob_'+self.dir_name+'.pickle')\n",
    "        ed3=self._classify_and_count(pred_prob_list, is_prob=True)\n",
    "        ed4=self._prob_classify_and_count(pred_prob_list)\n",
    "        ed5, num_iter=self._expectation_maximization(self.y_train,pred_prob_list, 0.1)\n",
    "        self._count_diff(td,ed4)\n",
    "        self._count_diff1(td,ed5, num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "class text_processing():\n",
    "    def __init__(self):\n",
    "        self.__tok=TfidfVectorizer().build_tokenizer()\n",
    "        self.tfidf_ngrams=TfidfVectorizer(tokenizer=self.__tokenize, preprocessor=self.__preprocessor,ngram_range=(1,4),\n",
    "                                     analyzer=\"word\" ,binary=False, stop_words='english', lowercase=False)\n",
    "\n",
    "    def __tokenize(self, text):\n",
    "        if text.lower()!='not available\\n':\n",
    "            lemms=[]\n",
    "            wnl = WordNetLemmatizer()\n",
    "            #st = PorterStemmer()\n",
    "            for item in self.__tok(text):\n",
    "                if item.isalpha():\n",
    "                    lemms.append(wnl.lemmatize(item.lower()))\n",
    "                    #lemms.append(st.stem(item.lower()))\n",
    "                else:\n",
    "                    if item.isdigit():\n",
    "                        if int(item)>=1700 and int(item)<=2100:\n",
    "                            lemms.append('YEAR')\n",
    "                        else:\n",
    "                            lemms.append('DIGIT')\n",
    "                    else:\n",
    "                        #pass\n",
    "                        lemms.append(item)\n",
    "                        if item[-2:]=='th' and item[:-2].isdigit() or item[-2:]=='st' and item[:-2].isdigit() or item[-2:]=='nd'and item[:-2].isdigit() or item[-2:]=='rd'and item[:-2].isdigit():\n",
    "                            lemms.append('ORDERNUM')\n",
    "                        elif item[-2:]=='pm' and item[:-2].isdigit() or item[-2:]=='am' and item[:-2].isdigit():\n",
    "                            lemms.append('HOUR')\n",
    "                        elif item=='4EXCL' or item=='5QUEST' or item=='6POINT':\n",
    "                            lemms.append(item)\n",
    "                        else:\n",
    "                            lemms.append('NAME_NAME')\n",
    "                            #print(item)\n",
    "        else:\n",
    "            lemms=[]\n",
    "        #print(lemms)\n",
    "        return lemms\n",
    "\n",
    "    def __preprocessor(self, text):\n",
    "        patterns = [\n",
    "#link\n",
    "                (\"https?:\\/\\/\\S*\",\" HTTPLNK \"),\n",
    "#                (\"@[\\w_-]+\", \" SOME_USER \"),\n",
    "#smile\n",
    "                (\":\\)*\\)\", \" SMILELOO \"),\n",
    "                (\";\\)*\\)\",\"  SMILELOO \"),\n",
    "                (\";-\\)*\\)\",\" SMILELOO \"),\n",
    "                (\":\\]*\\]\",\" SMILELOO \"),\n",
    "                (\"=D[^a-z^1-9$]\",\" SMILELOO \"),\n",
    "                (\";D[^a-z^1-9^$]\",\" SMILELOO \"),\n",
    "                (\":D[^a-z^1-9^$]\",\" SMILELOO \"),\n",
    "                (\":-D[^a-z^1-9^$]\",\" SMILELOO \"),\n",
    "#frown\n",
    "                (\":\\(*\\(\",\"  FROWNLO \"),\n",
    "                (\":-\\(*\\(\",\"  FROWNLO \"),\n",
    "#several exclamations, quetsions, points\n",
    "                (\"\\!*\\!\",\" 4EXCL \"),\n",
    "                (\"\\?*\\?\",\" 5QUEST \"),\n",
    "                (\"\\.*\\.\",\" 3POINT \"),\n",
    "#negation\n",
    "                (\"n't\",\"n not\")\n",
    "        ]\n",
    "        for pat, sub in patterns:\n",
    "            text=re.sub(pat, sub, text) #замена последовательная, порядок в паттерне имеет значение\n",
    "        return text\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "\n",
    "        return self.tfidf_ngrams.fit_transform(texts)\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        return self.tfidf_ngrams.transform(raw_documents)\n",
    "\n",
    "class char_processing():\n",
    "    def __init__(self):\n",
    "        self.__tok=TfidfVectorizer().build_tokenizer()\n",
    "        self.tfidf_ngrams=TfidfVectorizer(preprocessor=self.__preprocessor,ngram_range=(3,5),\n",
    "                                     analyzer=\"char\" ,binary=False, stop_words='english', lowercase=True)\n",
    "    def __preprocessor(self, text):\n",
    "        patterns = [\n",
    "#link\n",
    "                (\"https?:\\/\\/\\S*\",\" HTTPLNK \"),\n",
    "#                (\"@[\\w_-]+\", \" SOME_USER \"),\n",
    "#smile\n",
    "                (\":\\)*\\)\", \" SMILELOO \"),\n",
    "                (\";\\)*\\)\",\"  SMILELOO \"),\n",
    "                (\";-\\)*\\)\",\" SMILELOO \"),\n",
    "                (\":\\]*\\]\",\" SMILELOO \"),\n",
    "                (\"=D[^a-z^1-9$]\",\" SMILELOO \"),\n",
    "                (\";D[^a-z^1-9^$]\",\" SMILELOO \"),\n",
    "                (\":D[^a-z^1-9^$]\",\" SMILELOO \"),\n",
    "                (\":-D[^a-z^1-9^$]\",\" SMILELOO \"),\n",
    "#frown\n",
    "                (\":\\(*\\(\",\"  FROWNLO \"),\n",
    "                (\":-\\(*\\(\",\"  FROWNLO \"),\n",
    "#several exclamations, quetsions, points\n",
    "                (\"\\!*\\!\",\" 4EXCL \"),\n",
    "                (\"\\?*\\?\",\" 5QUEST \"),\n",
    "                (\"\\.*\\.\",\" 3POINT \"),\n",
    "#negation\n",
    "                (\"n't\",\"n not\")\n",
    "        ]\n",
    "        for pat, sub in patterns:\n",
    "            text=re.sub(pat, sub, text) #замена последовательная, порядок в паттерне имеет значение\n",
    "        return text\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        return self.tfidf_ngrams.fit_transform(texts)\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        return self.tfidf_ngrams.transform(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp=text_processing()\n",
    "cp=char_processing()\n",
    "\n",
    "Xw_train=tp.fit_transform(tweets)\n",
    "Xc_train=cp.fit_transform(tweets)\n",
    "Xw_train,Xw_test= Xw_train[:size],Xw_train[size:]\n",
    "Xc_train,Xc_test = Xc_train[:size],Xc_train[size:]\n",
    "X_train_NV=scipy.sparse.hstack((Xw_train, Xc_train), format='csr')\n",
    "X_test_NV=scipy.sparse.hstack((Xw_test, Xc_test), format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPETITION: TF-IDF, CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Quantification(method='Iter1')\n",
    "q.fit(X_train_NV, y_train)\n",
    "cc = q.predict(X_test_NV)\n",
    "cc = cc.tolist()\n",
    "cc.reverse()\n",
    "\n",
    "print(kld(CC(y_test),(cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPETITION: myTF-IDF,CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Quantification(method='Iter1')\n",
    "q.fit(X_train_tf_idf, y_train)\n",
    "cc = q.predict(X_test_tf_idf)\n",
    "cc = cc.tolist()\n",
    "cc.reverse()\n",
    "print(kld(CC(y_test),(cc)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPETITION: W2V, CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Quantification(method='Iter1')\n",
    "q.fit(X_train_w2v, y_train)\n",
    "cc = q.predict(X_test_w2v)\n",
    "cc = cc.tolist()\n",
    "cc.reverse()\n",
    "print(kld(CC(y_test),(cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPETITION: W2V, CODE (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Quantification(method='CC')\n",
    "q.fit(X_train_w2v, y_train)\n",
    "cc = q.predict(X_test_w2v)\n",
    "cc = cc.tolist()\n",
    "cc.reverse()\n",
    "print(kld(CC(y_test),(cc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
